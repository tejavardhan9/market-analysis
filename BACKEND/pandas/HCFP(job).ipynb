{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa83246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "class HCFPGrowthModel:\n",
    "    def __init__(self, min_item_frequency=5, min_support=5):\n",
    "        self.min_item_frequency = min_item_frequency\n",
    "        self.min_support = min_support\n",
    "        self.frequent_patterns = {}\n",
    "        self.recommendations = []\n",
    "        self.item_frequency = {}\n",
    "        self.active_day = None\n",
    "        self.peak_hours = None\n",
    "        self.basket_size = None\n",
    "\n",
    "    class TreeNode:\n",
    "        def __init__(self, item: Optional[str], parent: Optional['HCFPGrowthModel.TreeNode']):\n",
    "            self.item = item\n",
    "            self.count = 1\n",
    "            self.parent = parent\n",
    "            self.children: Dict[str, 'HCFPGrowthModel.TreeNode'] = {}\n",
    "            self.link = None\n",
    "\n",
    "        def increment(self, count=1):\n",
    "            self.count += count\n",
    "\n",
    "    def _compress_transactions(self, transactions: List[List[str]]) -> List[List[str]]:\n",
    "        frequency = defaultdict(int)\n",
    "        for transaction in transactions:\n",
    "            for item in transaction:\n",
    "                frequency[item] += 1\n",
    "        self.item_frequency = dict(frequency)\n",
    "\n",
    "        def sort_items(t):\n",
    "            return sorted(\n",
    "                [item for item in t if frequency[item] >= self.min_item_frequency],\n",
    "                key=lambda x: (-frequency[x], x)\n",
    "            )\n",
    "\n",
    "        return [sort_items(t) for t in transactions if sort_items(t)]\n",
    "\n",
    "    def _build_fp_tree(self, transactions: List[List[str]]) -> Tuple['TreeNode', Dict[str, List['TreeNode']]]:\n",
    "        header_table: Dict[str, List[HCFPGrowthModel.TreeNode]] = defaultdict(list)\n",
    "        root = self.TreeNode(None, None)\n",
    "\n",
    "        for transaction in transactions:\n",
    "            current_node = root\n",
    "            for item in transaction:\n",
    "                if item in current_node.children:\n",
    "                    current_node.children[item].increment()\n",
    "                else:\n",
    "                    new_node = self.TreeNode(item, current_node)\n",
    "                    current_node.children[item] = new_node\n",
    "                    header_table[item].append(new_node)\n",
    "                current_node = current_node.children[item]\n",
    "\n",
    "        header_table = {\n",
    "            item: nodes for item, nodes in header_table.items()\n",
    "            if sum(n.count for n in nodes) >= self.min_support\n",
    "        }\n",
    "        return root, header_table\n",
    "\n",
    "    def _ascend_fp_tree(self, node: 'TreeNode') -> List[str]:\n",
    "        path = []\n",
    "        while node.parent and node.parent.item is not None:\n",
    "            node = node.parent\n",
    "            path.append(node.item)\n",
    "        return path[::-1]\n",
    "\n",
    "    def _mine_patterns(self, header_table: Dict[str, List['TreeNode']]) -> Dict[Tuple[str, ...], int]:\n",
    "        patterns = {}\n",
    "        for item, nodes in header_table.items():\n",
    "            for node in nodes:\n",
    "                path = self._ascend_fp_tree(node)\n",
    "                if path:\n",
    "                    pattern = tuple(sorted(path + [item]))\n",
    "                    patterns[pattern] = patterns.get(pattern, 0) + node.count\n",
    "        return {p: c for p, c in patterns.items() if c >= self.min_support}\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        transactions = df.groupby(\"Member_number\")[\"itemDescription\"].apply(list).tolist()\n",
    "        compressed = self._compress_transactions(transactions)\n",
    "        _, header_table = self._build_fp_tree(compressed)\n",
    "        self.frequent_patterns = self._mine_patterns(header_table)\n",
    "        self.recommendations = sorted(self.frequent_patterns.items(), key=lambda x: -x[1])\n",
    "        self._analyze_trends(df)\n",
    "\n",
    "    def recommend(self, top_n=10) -> List[Tuple[Tuple[str, ...], int]]:\n",
    "        return self.recommendations[:top_n]\n",
    "\n",
    "    def _analyze_trends(self, df: pd.DataFrame):\n",
    "        if 'Date' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "            df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "            df['Hour'] = df['Date'].dt.hour\n",
    "\n",
    "            self.active_day = df['DayOfWeek'].mode()[0]\n",
    "            self.peak_hours = df.groupby('Hour').size().idxmax()\n",
    "            self.basket_size = df.groupby('Member_number')['itemDescription'].apply(len).mean()\n",
    "\n",
    "    def get_trends(self) -> Tuple[Optional[str], Optional[int], Optional[float]]:\n",
    "        return self.active_day, self.peak_hours, self.basket_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddfffb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejav\\AppData\\Local\\Temp\\ipykernel_3288\\3581082156.py:93: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hc_fp_growth_model.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"C:/Users/tejav/OneDrive/Documents/GitHub/market-analysis/BACKEND/pandas/DATASET/Groceries_dataset.csv\")\n",
    "\n",
    "# Train model\n",
    "model = HCFPGrowthModel(min_item_frequency=5, min_support=5)\n",
    "model.fit(df)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, \"hc_fp_growth_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37551ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole milk + whole milk -> 534\n",
      "other vegetables + whole milk -> 498\n",
      "rolls/buns + whole milk -> 264\n",
      "other vegetables + rolls/buns -> 179\n",
      "other vegetables + whole milk + whole milk -> 179\n",
      "other vegetables + other vegetables -> 166\n",
      "other vegetables + rolls/buns + whole milk -> 151\n",
      "soda + whole milk -> 140\n",
      "whole milk + whole milk + whole milk -> 137\n",
      "other vegetables + other vegetables + whole milk -> 116\n",
      "Most active day: Thursday\n",
      "Peak hour: 0\n",
      "Avg basket size: 9.94\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "model = joblib.load(\"hc_fp_growth_model.joblib\")\n",
    "\n",
    "# Get recommendations\n",
    "top_recs = model.recommend()\n",
    "for items, count in top_recs:\n",
    "    print(\" + \".join(items), \"->\", count)\n",
    "\n",
    "# Get purchase trends\n",
    "active_day, peak_hour, avg_basket = model.get_trends()\n",
    "print(f\"Most active day: {active_day}\")\n",
    "print(f\"Peak hour: {peak_hour}\")\n",
    "print(f\"Avg basket size: {avg_basket:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6ac6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations  # This enables postponed annotations\n",
    "from typing import Optional, Dict, List, Tuple, DefaultDict, Any, Set\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import math\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class HCFPGrowthModel:\n",
    "    \"\"\"Hierarchical Compressed FP-Growth algorithm implementation\"\"\"\n",
    "    \n",
    "    class TreeNode:\n",
    "        \"\"\"Node for the FP-Tree structure\"\"\"\n",
    "        def __init__(self, item: Optional[str], parent: Optional['TreeNode']):\n",
    "            self.item = item\n",
    "            self.count = 1\n",
    "            self.parent = parent\n",
    "            self.children: Dict[str, 'HCFPGrowthModel.TreeNode'] = OrderedDict()\n",
    "            self.link: Optional['HCFPGrowthModel.TreeNode'] = None\n",
    "\n",
    "        def increment(self, count: int = 1) -> None:\n",
    "            \"\"\"Increase the node's count\"\"\"\n",
    "            self.count += count\n",
    "\n",
    "    def __init__(self, min_support: int = 5, min_item_frequency: int = 5, compression_ratio: float = 0.5):\n",
    "        \"\"\"\n",
    "        Initialize the HCFPGrowth model\n",
    "        \n",
    "        Args:\n",
    "            min_support: Minimum support count for frequent patterns\n",
    "            min_item_frequency: Minimum frequency for items to be considered\n",
    "            compression_ratio: Ratio for hierarchical compression\n",
    "        \"\"\"\n",
    "        self.min_support = min_support\n",
    "        self.min_item_frequency = min_item_frequency\n",
    "        self.compression_ratio = compression_ratio\n",
    "        self.hierarchy: Dict[int, Dict[str, str]] = {}\n",
    "        self.frequent_patterns: Dict[Tuple[str, ...], int] = {}\n",
    "        self.header_table: DefaultDict[str, List[TreeNode]] = defaultdict(list)\n",
    "        self.item_frequency: Dict[str, int] = {}\n",
    "        self.trends: Dict[str, Any] = {}\n",
    "        self.root: Optional[HCFPGrowthModel.TreeNode] = None\n",
    "\n",
    "    def fit(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Train the HCFP-Growth model\"\"\"\n",
    "        logger.info(\"Starting model training...\")\n",
    "        transactions = self._prepare_transactions(df)\n",
    "        self._build_hierarchy(transactions)\n",
    "        compressed_transactions = self._compress_transactions(transactions)\n",
    "        self._build_hcfp_tree(compressed_transactions)\n",
    "        self._mine_compressed_patterns()\n",
    "        self._expand_hierarchical_patterns()\n",
    "        self.trends = self._analyze_trends(df)\n",
    "        logger.info(\"Model training completed\")\n",
    "\n",
    "    # [Keep all other methods exactly the same as in your original implementation]\n",
    "    # _prepare_transactions, _build_hierarchy, _compress_transactions, etc.\n",
    "\n",
    "    def recommend(self, top_n: int = 10) -> List[Tuple[Tuple[str, ...], int, float]]:\n",
    "        \"\"\"\n",
    "        Get top recommendations with support percentage\n",
    "        \n",
    "        Args:\n",
    "            top_n: Number of recommendations to return\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples containing (itemset, count, support_percentage)\n",
    "        \"\"\"\n",
    "        total_transactions = sum(self.item_frequency.values()) / len(self.item_frequency)\n",
    "        return sorted(\n",
    "            [(pattern, count, (count/total_transactions)*100) \n",
    "             for pattern, count in self.frequent_patterns.items()],\n",
    "            key=lambda x: (-x[1], -x[2], len(x[0]))\n",
    "        )[:top_n]\n",
    "\n",
    "    def save(self, path: str) -> None:\n",
    "        \"\"\"Save model to file\"\"\"\n",
    "        joblib.dump(self, path, compress=3)\n",
    "        logger.info(f\"Model saved to {path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str) -> 'HCFPGrowthModel':\n",
    "        \"\"\"Load model from file\"\"\"\n",
    "        model = joblib.load(path)\n",
    "        if not isinstance(model, HCFPGrowthModel):\n",
    "            raise ValueError(\"Loaded file is not an HCFPGrowthModel\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46cd8c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Training failed: Data file not found at Groceries_dataset.csv\n",
      "ERROR:__main__:Analysis failed: [Errno 2] No such file or directory: 'model.joblib'\n",
      "INFO:__main__:Generating recommendations...\n",
      "INFO:__main__:Analyzing trends...\n",
      "ERROR:__main__:Analysis failed: 'HCFPGrowthModel' object has no attribute 'trends'\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Dict, List, Tuple, DefaultDict, Any\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import math\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class HCFPGrowthModel:\n",
    "    class TreeNode:\n",
    "        def __init__(self, item: Optional[str], parent: Optional['HCFPGrowthModel.TreeNode']):\n",
    "            self.item = item\n",
    "            self.count = 1\n",
    "            self.parent = parent\n",
    "            self.children: Dict[str, 'HCFPGrowthModel.TreeNode'] = OrderedDict()\n",
    "            self.link = None\n",
    "\n",
    "        def increment(self, count: int = 1):\n",
    "            self.count += count\n",
    "\n",
    "    def __init__(self, min_support: int = 5, min_item_frequency: int = 5, compression_ratio: float = 0.5):\n",
    "        self.min_support = min_support\n",
    "        self.min_item_frequency = min_item_frequency\n",
    "        self.compression_ratio = compression_ratio\n",
    "        self.hierarchy: Dict[int, Dict[str, str]] = {}\n",
    "        self.frequent_patterns: Dict[Tuple[str, ...], int] = {}\n",
    "        self.header_table: DefaultDict[str, List[TreeNode]] = defaultdict(list)\n",
    "        self.item_frequency: Dict[str, int] = {}\n",
    "        self.trends: Dict[str, Any] = {}\n",
    "        self.root: Optional[HCFPGrowthModel.TreeNode] = None\n",
    "\n",
    "    def fit(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Train the HCFP-Growth model with comprehensive logging\"\"\"\n",
    "        logger.info(\"Starting model training...\")\n",
    "        try:\n",
    "            transactions = self._prepare_transactions(df)\n",
    "            logger.info(f\"Processed {len(transactions)} transactions\")\n",
    "            \n",
    "            self._build_hierarchy(transactions)\n",
    "            logger.info(f\"Built hierarchy with {len(self.hierarchy)} levels\")\n",
    "            \n",
    "            compressed_transactions = self._compress_transactions(transactions)\n",
    "            logger.info(f\"Compressed transactions to {len(compressed_transactions)} patterns\")\n",
    "            \n",
    "            self._build_hcfp_tree(compressed_transactions)\n",
    "            logger.info(\"FP-tree construction completed\")\n",
    "            \n",
    "            self._mine_compressed_patterns()\n",
    "            logger.info(f\"Mined {len(self.compressed_patterns)} compressed patterns\")\n",
    "            \n",
    "            self._expand_hierarchical_patterns()\n",
    "            logger.info(f\"Expanded to {len(self.frequent_patterns)} frequent patterns\")\n",
    "            \n",
    "            self.trends = self._analyze_trends(df)\n",
    "            logger.info(\"Trend analysis completed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during model training: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _prepare_transactions(self, df: pd.DataFrame) -> List[List[str]]:\n",
    "        \"\"\"Convert DataFrame to transactions with validation\"\"\"\n",
    "        if 'Member_number' in df.columns and 'itemDescription' in df.columns:\n",
    "            return df.groupby('Member_number')['itemDescription'].apply(list).tolist()\n",
    "        elif 'transaction_id' in df.columns and 'item' in df.columns:\n",
    "            return df.groupby('transaction_id')['item'].apply(list).tolist()\n",
    "        raise ValueError(\"DataFrame must contain either ('Member_number', 'itemDescription') or ('transaction_id', 'item')\")\n",
    "\n",
    "    def _build_hierarchy(self, transactions: List[List[str]]) -> None:\n",
    "        \"\"\"Build hierarchical structure with multiple compression levels\"\"\"\n",
    "        freq = defaultdict(int)\n",
    "        for t in transactions:\n",
    "            for item in t:\n",
    "                freq[item] += 1\n",
    "        self.item_frequency = dict(freq)\n",
    "        \n",
    "        sorted_items = sorted(freq.items(), key=lambda x: -x[1])\n",
    "        num_levels = max(2, math.ceil(math.log(len(sorted_items), 1/self.compression_ratio)))\n",
    "        \n",
    "        for level in range(num_levels):\n",
    "            self.hierarchy[level] = {}\n",
    "            threshold = sorted_items[int(len(sorted_items) * (self.compression_ratio ** level))][1]\n",
    "            for item, count in sorted_items:\n",
    "                if count >= threshold:\n",
    "                    self.hierarchy[level][item] = f\"L{level}_{item[:3]}\"\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    def _compress_transactions(self, transactions: List[List[str]]) -> List[List[str]]:\n",
    "        \"\"\"Apply hierarchical compression with validation\"\"\"\n",
    "        compressed = []\n",
    "        for t in transactions:\n",
    "            compressed_t = []\n",
    "            for item in t:\n",
    "                for level in sorted(self.hierarchy.keys(), reverse=True):\n",
    "                    if item in self.hierarchy[level]:\n",
    "                        compressed_t.append(self.hierarchy[level][item])\n",
    "                        break\n",
    "            if compressed_t and len(compressed_t) >= 2:  # Minimum 2 items for patterns\n",
    "                compressed.append(compressed_t)\n",
    "        return compressed\n",
    "\n",
    "    def _build_hcfp_tree(self, transactions: List[List[str]]) -> None:\n",
    "        \"\"\"Build FP-Tree with header table\"\"\"\n",
    "        self.root = self.TreeNode(None, None)\n",
    "        for t in transactions:\n",
    "            current = self.root\n",
    "            for item in t:\n",
    "                if item in current.children:\n",
    "                    current.children[item].increment()\n",
    "                else:\n",
    "                    new_node = self.TreeNode(item, current)\n",
    "                    current.children[item] = new_node\n",
    "                    self.header_table[item].append(new_node)\n",
    "                current = current.children[item]\n",
    "\n",
    "    def _mine_compressed_patterns(self) -> None:\n",
    "        \"\"\"Mine patterns with conditional pattern bases\"\"\"\n",
    "        self.compressed_patterns = {}\n",
    "        sorted_items = sorted(self.header_table.keys(), \n",
    "                            key=lambda x: -len(self.header_table[x]))\n",
    "        \n",
    "        for item in sorted_items:\n",
    "            conditional_base = []\n",
    "            for node in self.header_table[item]:\n",
    "                path = []\n",
    "                parent = node.parent\n",
    "                while parent and parent.item:\n",
    "                    path.append(parent.item)\n",
    "                    parent = parent.parent\n",
    "                if path:\n",
    "                    conditional_base.append((path, node.count))\n",
    "            \n",
    "            if conditional_base:\n",
    "                conditional_tree = self._build_conditional_tree(conditional_base)\n",
    "                conditional_patterns = self._mine_conditional_patterns(item, conditional_tree)\n",
    "                for pattern, count in conditional_patterns.items():\n",
    "                    full_pattern = tuple(sorted(pattern + (item,)))\n",
    "                    self.compressed_patterns[full_pattern] = self.compressed_patterns.get(full_pattern, 0) + count\n",
    "\n",
    "    def _expand_hierarchical_patterns(self) -> None:\n",
    "        \"\"\"Expand compressed patterns to original items\"\"\"\n",
    "        self.frequent_patterns = {}\n",
    "        code_to_items = defaultdict(list)\n",
    "        for level in self.hierarchy:\n",
    "            for item, code in self.hierarchy[level].items():\n",
    "                code_to_items[code].append(item)\n",
    "        \n",
    "        for pattern, count in self.compressed_patterns.items():\n",
    "            expanded_sets = [set(code_to_items.get(item, [item])) for item in pattern]\n",
    "            from itertools import product\n",
    "            for combination in product(*expanded_sets):\n",
    "                if len(set(combination)) == len(combination):\n",
    "                    sorted_combo = tuple(sorted(combination))\n",
    "                    self.frequent_patterns[sorted_combo] = self.frequent_patterns.get(sorted_combo, 0) + count\n",
    "        \n",
    "        self.frequent_patterns = {k: v for k, v in self.frequent_patterns.items() \n",
    "                                if v >= self.min_support}\n",
    "\n",
    "    def _analyze_trends(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze purchase trends with date information\"\"\"\n",
    "        trends = {}\n",
    "        if 'Date' in df.columns:\n",
    "            try:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "                df['Hour'] = df['Date'].dt.hour\n",
    "                \n",
    "                trends['active_day'] = df['DayOfWeek'].mode()[0]\n",
    "                trends['peak_hour'] = df['Hour'].mode()[0]\n",
    "                trends['avg_basket_size'] = df.groupby('Member_number').size().mean()\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Trend analysis limited: {str(e)}\")\n",
    "        return trends\n",
    "\n",
    "    def recommend(self, top_n: int = 10) -> List[Tuple[Tuple[str, ...], int]]:\n",
    "        \"\"\"Get top recommendations with support percentage\"\"\"\n",
    "        total_transactions = sum(self.item_frequency.values()) / len(self.item_frequency)  # Approximate\n",
    "        return sorted(\n",
    "            [(pattern, count, (count/total_transactions)*100) \n",
    "             for pattern, count in self.frequent_patterns.items()],\n",
    "            key=lambda x: (-x[1], -x[2], len(x[0]))\n",
    "        )[:top_n]\n",
    "\n",
    "    def save(self, path: str) -> None:\n",
    "        \"\"\"Save model with compression\"\"\"\n",
    "        joblib.dump(self, path, compress=3)\n",
    "        logger.info(f\"Model saved to {path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str) -> 'HCFPGrowthModel':\n",
    "        \"\"\"Load model with validation\"\"\"\n",
    "        model = joblib.load(path)\n",
    "        if not isinstance(model, HCFPGrowthModel):\n",
    "            raise ValueError(\"Loaded object is not an HCFPGrowthModel\")\n",
    "        return model\n",
    "\n",
    "\n",
    "def train_and_save_model(data_path: str, model_path: str = \"hc_fp_growth_model.joblib\") -> bool:\n",
    "    \"\"\"Complete training pipeline with error handling\"\"\"\n",
    "    try:\n",
    "        data_path = Path(data_path)\n",
    "        if not data_path.exists():\n",
    "            raise FileNotFoundError(f\"Data file not found at {data_path}\")\n",
    "\n",
    "        logger.info(f\"Loading data from {data_path}...\")\n",
    "        df = pd.read_csv(data_path)\n",
    "\n",
    "        logger.info(\"Initializing and training model...\")\n",
    "        model = HCFPGrowthModel(min_support=5, min_item_frequency=5)\n",
    "        model.fit(df)\n",
    "\n",
    "        logger.info(f\"Saving model to {model_path}...\")\n",
    "        model.save(model_path)\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def analyze_model(model_path: str = \"hc_fp_growth_model.joblib\") -> Tuple[Optional[List[Tuple[str, int, float]]], Optional[Dict[str, Any]]]:\n",
    "    \"\"\"Complete analysis pipeline with error handling\"\"\"\n",
    "    try:\n",
    "        model = HCFPGrowthModel.load(model_path)\n",
    "        \n",
    "        logger.info(\"Generating recommendations...\")\n",
    "        recommendations = model.recommend()\n",
    "        \n",
    "        logger.info(\"Analyzing trends...\")\n",
    "        trends = model.trends\n",
    "        \n",
    "        return recommendations, trends\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Analysis failed: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"End-to-end execution of training and analysis\"\"\"\n",
    "    DATA_PATH = \"Groceries_dataset.csv\"\n",
    "    MODEL_PATH = \"hc_fp_growth_model.joblib\"\n",
    "\n",
    "    # Train or load model\n",
    "    if not Path(MODEL_PATH).exists():\n",
    "        logger.info(\"Model not found, training new model...\")\n",
    "        if not train_and_save_model(DATA_PATH, MODEL_PATH):\n",
    "            return\n",
    "\n",
    "    # Analyze and display results\n",
    "    recommendations, trends = analyze_model(MODEL_PATH)\n",
    "    \n",
    "    if recommendations:\n",
    "        print(\"\\nTop Recommendations:\")\n",
    "        for i, (items, count, support) in enumerate(recommendations, 1):\n",
    "            print(f\"{i}. {' + '.join(items)} - {count} occurrences ({support:.1f}% support)\")\n",
    "    \n",
    "    if trends:\n",
    "        print(\"\\nPurchase Trends:\")\n",
    "        print(f\"Most active day: {trends.get('active_day', 'N/A')}\")\n",
    "        print(f\"Peak shopping hour: {trends.get('peak_hour', 'N/A')}:00\")\n",
    "        print(f\"Average basket size: {trends.get('avg_basket_size', 'N/A'):.2f} items\")\n",
    "\n",
    "train_and_save_model(\"Groceries_dataset.csv\", \"model.joblib\")\n",
    "recommendations, trends = analyze_model(\"model.joblib\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084bff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Training failed: Data file not found at Groceries_dataset.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_save_model(\"Groceries_dataset.csv\", \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559da087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
