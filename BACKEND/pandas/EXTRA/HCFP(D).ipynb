{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca209e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequently Bought Together:\n",
      "Customers who bought whole milk also bought whole milk (13.70%).\n",
      "Customers who bought other vegetables also bought whole milk (12.78%).\n",
      "Customers who bought rolls/buns also bought whole milk (6.77%).\n",
      "Customers who bought other vegetables also bought rolls/buns (4.59%).\n",
      "Customers who bought other vegetables also bought whole milk (4.59%).\n",
      "Customers who bought other vegetables also bought other vegetables (4.26%).\n",
      "Customers who bought other vegetables also bought rolls/buns (3.87%).\n",
      "Customers who bought soda also bought whole milk (3.59%).\n",
      "Customers who bought whole milk also bought whole milk (3.51%).\n",
      "Customers who bought other vegetables also bought other vegetables (2.98%).\n",
      "\n",
      "Top Recommendations:\n",
      "Based on your history, we recommend:\n",
      "\n",
      "whole milk + whole milk combo\n",
      "other vegetables + whole milk combo\n",
      "rolls/buns + whole milk combo\n",
      "other vegetables + rolls/buns combo\n",
      "other vegetables + whole milk + whole milk combo\n",
      "other vegetables + other vegetables combo\n",
      "other vegetables + rolls/buns + whole milk combo\n",
      "soda + whole milk combo\n",
      "whole milk + whole milk + whole milk combo\n",
      "other vegetables + other vegetables + whole milk combo\n",
      "\n",
      "Purchase Trends:\n",
      "Most active shopping day: Thursday\n",
      "Peak shopping hours: 0:00\n",
      "Average basket size: 9.94 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejav\\AppData\\Local\\Temp\\ipykernel_13932\\4121836114.py:82: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:/Users/tejav/OneDrive/Documents/GitHub/market-analysis/BACKEND/pandas/DATASET/Groceries_dataset.csv\")\n",
    "transactions = df.groupby(\"Member_number\")[\"itemDescription\"].apply(list).tolist()\n",
    "\n",
    "# Step 1: Compress transactions based on item frequency\n",
    "def compress_transactions(transactions: List[List[str]], min_item_frequency: int = 2) -> Tuple[List[List[str]], Dict[str, int]]:\n",
    "    frequency = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            frequency[item] += 1\n",
    "\n",
    "    def sort_items(t):\n",
    "        return sorted([item for item in t if frequency[item] >= min_item_frequency], key=lambda x: (-frequency[x], x))\n",
    "\n",
    "    compressed = [sort_items(t) for t in transactions if sort_items(t)]\n",
    "    return compressed, frequency\n",
    "\n",
    "# Step 2: FP-Tree Node Definition\n",
    "class TreeNode:\n",
    "    def __init__(self, item: Optional[str], parent: Optional['TreeNode']):\n",
    "        self.item = item\n",
    "        self.count = 1\n",
    "        self.parent = parent\n",
    "        self.children: Dict[str, 'TreeNode'] = {}\n",
    "        self.link = None\n",
    "\n",
    "    def increment(self, count=1):\n",
    "        self.count += count\n",
    "\n",
    "# Step 3: Build FP-Tree from compressed transactions\n",
    "def build_fp_tree(transactions: List[List[str]], min_support: int) -> Tuple[TreeNode, Dict[str, List[TreeNode]]]:\n",
    "    header_table: Dict[str, List[TreeNode]] = defaultdict(list)\n",
    "    root = TreeNode(None, None)\n",
    "\n",
    "    for transaction in transactions:\n",
    "        current_node = root\n",
    "        for item in transaction:\n",
    "            if item in current_node.children:\n",
    "                current_node.children[item].increment()\n",
    "            else:\n",
    "                new_node = TreeNode(item, current_node)\n",
    "                current_node.children[item] = new_node\n",
    "                header_table[item].append(new_node)\n",
    "            current_node = current_node.children[item]\n",
    "\n",
    "    header_table = {\n",
    "        item: nodes for item, nodes in header_table.items()\n",
    "        if sum(n.count for n in nodes) >= min_support\n",
    "    }\n",
    "\n",
    "    return root, header_table\n",
    "\n",
    "# Step 4: Mine Frequent Patterns from the FP-tree\n",
    "def ascend_fp_tree(node: TreeNode) -> List[str]:\n",
    "    path = []\n",
    "    while node.parent and node.parent.item is not None:\n",
    "        node = node.parent\n",
    "        path.append(node.item)\n",
    "    return path[::-1]\n",
    "\n",
    "def mine_patterns(header_table: Dict[str, List[TreeNode]], min_support: int) -> Dict[Tuple[str, ...], int]:\n",
    "    patterns = {}\n",
    "    for item, nodes in header_table.items():\n",
    "        for node in nodes:\n",
    "            path = ascend_fp_tree(node)\n",
    "            if path:\n",
    "                pattern = tuple(sorted(path + [item]))\n",
    "                patterns[pattern] = patterns.get(pattern, 0) + node.count\n",
    "    return {pattern: count for pattern, count in patterns.items() if count >= min_support}\n",
    "\n",
    "# Step 5: Generate Recommendations from Patterns\n",
    "def generate_recommendations(patterns: Dict[Tuple[str, ...], int]) -> List[Tuple[Tuple[str, ...], int]]:\n",
    "    return sorted(patterns.items(), key=lambda x: -x[1])\n",
    "\n",
    "# Step 6: Purchase Trend Analysis (if Date column exists)\n",
    "def analyze_purchase_trends(df: pd.DataFrame):\n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "        df['Hour'] = df['Date'].dt.hour\n",
    "\n",
    "        # Most active shopping day\n",
    "        active_day = df['DayOfWeek'].mode()[0]\n",
    "\n",
    "        # Peak shopping hours\n",
    "        peak_hours = df.groupby('Hour').size().idxmax()\n",
    "\n",
    "        # Average basket size\n",
    "        basket_size = df.groupby('Member_number')['itemDescription'].apply(len).mean()\n",
    "\n",
    "        return active_day, peak_hours, basket_size\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "# Step 7: Run the Algorithm\n",
    "# Compress Transactions\n",
    "compressed_tx, item_freq = compress_transactions(transactions, min_item_frequency=5)\n",
    "\n",
    "# Build FP-Tree\n",
    "fp_root, header_table = build_fp_tree(compressed_tx, min_support=5)\n",
    "\n",
    "# Mine Frequent Patterns\n",
    "frequent_patterns = mine_patterns(header_table, min_support=5)\n",
    "\n",
    "# Generate Recommendations\n",
    "recommendations = generate_recommendations(frequent_patterns)\n",
    "\n",
    "# Purchase Trend Analysis (assuming the 'Date' column exists)\n",
    "active_day, peak_hours, basket_size = analyze_purchase_trends(df)\n",
    "\n",
    "# Display Results\n",
    "print(\"Frequently Bought Together:\")\n",
    "for items, count in recommendations[:10]:\n",
    "    items_str = \" + \".join(items)\n",
    "    confidence = (count / len(transactions)) * 100\n",
    "    print(f\"Customers who bought {items[0]} also bought {items[1]} ({confidence:.2f}%).\")\n",
    "\n",
    "print(\"\\nTop Recommendations:\")\n",
    "print(\"Based on your history, we recommend:\\n\")\n",
    "for items, count in recommendations[:10]:\n",
    "    items_str = \" + \".join(items)\n",
    "    print(f\"{items_str} combo\")\n",
    "\n",
    "print(\"\\nPurchase Trends:\")\n",
    "if active_day:\n",
    "    print(f\"Most active shopping day: {active_day}\")\n",
    "    print(f\"Peak shopping hours: {peak_hours}:00\")\n",
    "    print(f\"Average basket size: {basket_size:.2f} items\")\n",
    "else:\n",
    "    print(\"Purchase trend analysis is unavailable (missing 'Date' column).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d83539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2ba84b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m joblib.dump(\u001b[43mmodel\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mmodel.joblib\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, 'model.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
